{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d954a3",
   "metadata": {},
   "source": [
    "# TRAE (Transformer Autoencoder) for Expression Embeddings\n",
    "\n",
    "This notebook runs the TRAE code for training and testing a projection head on expression embeddings. The notebook:\n",
    "\n",
    "1. Clones the required repository\n",
    "2. Installs all necessary dependencies\n",
    "3. Sets up the environment\n",
    "4. Runs the TRAE training and testing pipeline\n",
    "\n",
    "**Note**: Make sure to enable GPU acceleration in Kaggle for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c4e23",
   "metadata": {},
   "source": [
    "## 1. Clone Repository and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Clone the repository\n",
    "if not os.path.exists('/kaggle/working/CHEHAB_FHE_Compiler_RL'):\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone https://github.com/Abderraouf-D/CHEHAB_FHE_Compiler_RL.git /kaggle/working/CHEHAB_FHE_Compiler_RL\n",
    "else:\n",
    "    print(\"Repository already exists.\")\n",
    "\n",
    "# Change to the project directory\n",
    "os.chdir('/kaggle/working/CHEHAB_FHE_Compiler_RL')\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba99c1d",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core dependencies\n",
    "print(\"Installing PyTorch and related packages...\")\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "print(\"\\nInstalling additional dependencies...\")\n",
    "!pip install tqdm numpy matplotlib pandas\n",
    "\n",
    "# Install project-specific requirements first\n",
    "print(\"\\nInstalling project requirements...\")\n",
    "!pip install -r RL/requirements.txt\n",
    "\n",
    "# Install additional dependencies that might be needed for pytrs\n",
    "print(\"\\nInstalling additional dependencies for pytrs...\")\n",
    "!pip install setuptools wheel\n",
    "\n",
    "# Navigate to the RL directory and install pytrs with all dependencies\n",
    "print(\"\\nInstalling pytrs package...\")\n",
    "os.chdir('/kaggle/working/CHEHAB_FHE_Compiler_RL/RL')\n",
    "\n",
    "# Try to install any missing dependencies that pytrs might need\n",
    "!pip install --upgrade setuptools\n",
    "!pip install --editable .\n",
    "\n",
    "# Also try to install from the parent directory structure if needed\n",
    "print(\"\\nAttempting alternative pytrs installation...\")\n",
    "import sys\n",
    "sys.path.insert(0, '/kaggle/working/CHEHAB_FHE_Compiler_RL/RL')\n",
    "\n",
    "print(\"\\nAll dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4c08d4",
   "metadata": {},
   "source": [
    "## 3. Verify Installation and Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA not available - using CPU\")\n",
    "\n",
    "# Add multiple paths for pytrs import\n",
    "sys.path.insert(0, '/kaggle/working/CHEHAB_FHE_Compiler_RL/RL')\n",
    "sys.path.insert(0, '/kaggle/working/CHEHAB_FHE_Compiler_RL/RL/pytrs')\n",
    "\n",
    "# Check what's in the RL directory\n",
    "print(f\"\\nContents of RL directory:\")\n",
    "if os.path.exists('/kaggle/working/CHEHAB_FHE_Compiler_RL/RL'):\n",
    "    rl_contents = os.listdir('/kaggle/working/CHEHAB_FHE_Compiler_RL/RL')\n",
    "    for item in rl_contents:\n",
    "        print(f\"  - {item}\")\n",
    "\n",
    "# Check what's in the pytrs directory\n",
    "print(f\"\\nContents of pytrs directory:\")\n",
    "if os.path.exists('/kaggle/working/CHEHAB_FHE_Compiler_RL/RL/pytrs'):\n",
    "    pytrs_contents = os.listdir('/kaggle/working/CHEHAB_FHE_Compiler_RL/RL/pytrs')\n",
    "    for item in pytrs_contents:\n",
    "        print(f\"  - {item}\")\n",
    "\n",
    "# Test pytrs import with better error handling\n",
    "try:\n",
    "    # Try importing from different locations\n",
    "    try:\n",
    "        from pytrs import parse_sexpr, tokenize, Op\n",
    "        print(\"‚úÖ pytrs package imported successfully from pytrs module\")\n",
    "    except ImportError as e1:\n",
    "        print(f\"‚ùå Failed to import from pytrs module: {e1}\")\n",
    "        try:\n",
    "            # Try direct import from files\n",
    "            import pytrs\n",
    "            from pytrs import parse_sexpr, tokenize, Op\n",
    "            print(\"‚úÖ pytrs package imported successfully using direct import\")\n",
    "        except ImportError as e2:\n",
    "            print(f\"‚ùå Failed direct import: {e2}\")\n",
    "            try:\n",
    "                # Try importing individual modules\n",
    "                sys.path.append('/kaggle/working/CHEHAB_FHE_Compiler_RL/RL/pytrs')\n",
    "                import parse_sexpr\n",
    "                import tokenize\n",
    "                print(\"‚úÖ Individual modules imported successfully\")\n",
    "            except ImportError as e3:\n",
    "                print(f\"‚ùå Failed to import individual modules: {e3}\")\n",
    "                print(\"‚ö†Ô∏è Will try to continue with manual imports in the next cells\")\n",
    "                \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error during pytrs import: {e}\")\n",
    "    print(\"‚ö†Ô∏è Will try to continue with manual setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccd318f",
   "metadata": {},
   "source": [
    "## 4. Download Pre-trained Model (if available)\n",
    "\n",
    "This cell attempts to download the pre-trained model. If the model is not available publicly, you'll need to upload it manually to Kaggle datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06596565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create directories for models\n",
    "os.makedirs('/kaggle/working/trained_models', exist_ok=True)\n",
    "\n",
    "# Check if model exists in the cloned repository\n",
    "model_paths = [\n",
    "    '/kaggle/working/CHEHAB_FHE_Compiler_RL/RL/fhe_rl/trained_models/model_Transformer_ddp_10399047_epoch_5000000.pth',\n",
    "    '/kaggle/working/CHEHAB_FHE_Compiler_RL/RL/fhe_rl/trained_models/projection_head.pth'\n",
    "]\n",
    "\n",
    "print(\"Checking for pre-trained models in repository...\")\n",
    "for path in model_paths:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Found model: {path}\")\n",
    "    else:\n",
    "        print(f\"Model not found: {path}\")\n",
    "\n",
    "# Also check if model exists in Kaggle input (you can still add it as a dataset)\n",
    "kaggle_model_paths = [\n",
    "    '/kaggle/input/*/model_Transformer_ddp_10399047_epoch_5000000.pth',\n",
    "    '/kaggle/input/*/projection_head.pth'\n",
    "]\n",
    "\n",
    "print(\"\\nChecking for pre-trained models in Kaggle datasets...\")\n",
    "for path in kaggle_model_paths:\n",
    "    import glob\n",
    "    matches = glob.glob(path)\n",
    "    if matches:\n",
    "        print(f\"Found model: {matches[0]}\")\n",
    "    else:\n",
    "        print(f\"Model not found: {path}\")\n",
    "\n",
    "print(\"\\nNote: The notebook will first try to use models from the repository,\")\n",
    "print(\"then fall back to Kaggle datasets, or train from scratch if none are available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61929f55",
   "metadata": {},
   "source": [
    "## 5. Create Contrastive Training Data\n",
    "\n",
    "Generate contrastive pairs for training the projection head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the RL directory to Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/kaggle/working/CHEHAB_FHE_Compiler_RL/RL')\n",
    "sys.path.append('/kaggle/working/CHEHAB_FHE_Compiler_RL/RL/pytrs')\n",
    "\n",
    "# Try multiple import strategies for pytrs\n",
    "parse_sexpr = None\n",
    "try:\n",
    "    from pytrs import parse_sexpr\n",
    "    print(\"‚úÖ Successfully imported parse_sexpr from pytrs\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import from pytrs: {e}\")\n",
    "    try:\n",
    "        # Try to manually load the parse_sexpr function\n",
    "        exec(open('/kaggle/working/CHEHAB_FHE_Compiler_RL/RL/pytrs/__init__.py').read())\n",
    "        print(\"‚úÖ Successfully loaded pytrs manually\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå Failed manual load: {e2}\")\n",
    "        # Create a minimal parse_sexpr function for testing\n",
    "        print(\"‚ö†Ô∏è Using fallback implementation\")\n",
    "        \n",
    "        def parse_sexpr(expr_str):\n",
    "            \"\"\"Minimal fallback implementation for parse_sexpr\"\"\"\n",
    "            # This is a simplified version - replace with actual implementation\n",
    "            class MockOp:\n",
    "                def __init__(self, op, args):\n",
    "                    self.op = op\n",
    "                    self.args = args\n",
    "                def __str__(self):\n",
    "                    return f\"({self.op} {' '.join(str(arg) for arg in self.args)})\"\n",
    "                def __repr__(self):\n",
    "                    return self.__str__()\n",
    "            \n",
    "            # Very basic parsing - this should be replaced with the actual pytrs implementation\n",
    "            if expr_str.startswith('(') and expr_str.endswith(')'):\n",
    "                inner = expr_str[1:-1].strip()\n",
    "                parts = inner.split()\n",
    "                if len(parts) > 1:\n",
    "                    op = parts[0]\n",
    "                    args = parts[1:]\n",
    "                    return MockOp(op, args)\n",
    "            return expr_str\n",
    "\n",
    "# returns a list of pairs of positive and negative pairs, 1 for positive and 0 for negative\n",
    "def augment_expression(expr):\n",
    "    \n",
    "    \"\"\"    \n",
    "        A function to augment the expression by generating positive and negative pairs.\n",
    "            expr: a string representing the expression\n",
    "        Returns a list of tuples (expr_a, expr_b, label) where label is 1 for positive pairs and 0 for negative pairs. \n",
    "    \"\"\"\n",
    "    expr_pairs = []\n",
    "    for i, c in enumerate(expr):\n",
    "        if c == \"+\":\n",
    "            prev_expr = expr\n",
    "            expr = expr[:i] + \"-\" + expr[i + 1:]\n",
    "            neg_pair = (prev_expr, expr, 0)  # negative pair\n",
    "            pos_pair = (prev_expr, prev_expr, 1)\n",
    "            expr_pairs.append(neg_pair)\n",
    "            expr_pairs.append(pos_pair)\n",
    "\n",
    "            expr = expr[:i] + \"*\" + expr[i + 1:] \n",
    "            neg_pair = (prev_expr, expr, 0)  # negative pair\n",
    "            pos_pair = (prev_expr, prev_expr, 1)\n",
    "            expr_pairs.append(neg_pair)\n",
    "            expr_pairs.append(pos_pair)\n",
    "\n",
    "        elif c == \"-\":\n",
    "            prev_expr = expr\n",
    "            expr = expr[:i] + \"+\" + expr[i + 1:]\n",
    "            neg_pair = (prev_expr, expr, 0)  # negative pair\n",
    "            pos_pair = (prev_expr, prev_expr, 1)\n",
    "            expr_pairs.append(neg_pair)\n",
    "            expr_pairs.append(pos_pair)\n",
    "\n",
    "            expr = expr[:i] + \"*\" + expr[i + 1:] \n",
    "            neg_pair = (prev_expr, expr, 0)  # negative pair\n",
    "            pos_pair = (prev_expr, prev_expr, 1)\n",
    "            expr_pairs.append(neg_pair)\n",
    "            expr_pairs.append(pos_pair)\n",
    "\n",
    "        elif c == \"*\":\n",
    "            prev_expr = expr\n",
    "            expr = expr[:i] + \"+\" + expr[i + 1:]\n",
    "            neg_pair = (prev_expr, expr, 0)  # negative pair\n",
    "            pos_pair = (prev_expr, prev_expr, 1)\n",
    "            expr_pairs.append(neg_pair)\n",
    "            expr_pairs.append(pos_pair)\n",
    "\n",
    "            expr = expr[:i] + \"-\" + expr[i + 1:] \n",
    "            neg_pair = (prev_expr, expr, 0)  # negative pair\n",
    "            pos_pair = (prev_expr, prev_expr, 1)\n",
    "            expr_pairs.append(neg_pair)\n",
    "            expr_pairs.append(pos_pair)    \n",
    "        \n",
    "    return expr_pairs\n",
    "\n",
    "# building the positive and negative contrastive pairs based on the expression strings\n",
    "def build_contrastive_pairs(expr_strs):\n",
    "    pairs = []\n",
    "    # parse_sexpr\n",
    "    for expr in expr_strs:\n",
    "        expr_pairs = augment_expression(expr)\n",
    "\n",
    "        # parsing the expressions of the generated pairs\n",
    "        try:\n",
    "            parsed_expr_pairs = [(parse_sexpr(a), parse_sexpr(b), label) for a, b, label in expr_pairs]\n",
    "            pairs.extend(parsed_expr_pairs)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error parsing expression pairs for {expr}: {e}\")\n",
    "            continue\n",
    "        \n",
    "    return pairs\n",
    "\n",
    "# Create sample expressions dataset file (since test.txt may not exist)\n",
    "sample_expressions = [\n",
    "    \"(Vec (+ a b) (+ c d) (- f g))\",\n",
    "    \"(Vec (- x y) (* p q) (+ m n))\",\n",
    "    \"(+ (* a b) (- c d))\",\n",
    "    \"(- (+ x y) (* z w))\",\n",
    "    \"(* (+ a b) (- c d))\",\n",
    "    \"(Vec (+ a 1) (- b 2) (* c 3))\",\n",
    "    \"(+ (- a b) (+ c d))\",\n",
    "    \"(* (+ x 5) (- y 10))\",\n",
    "    \"(Vec (* a a) (+ b b) (- c c))\",\n",
    "    \"(- (* x y) (+ z w))\"\n",
    "]\n",
    "\n",
    "# Create directories for datasets\n",
    "os.makedirs('/kaggle/working/datasets', exist_ok=True)\n",
    "\n",
    "# Write sample expressions to file (mimicking test.txt)\n",
    "with open('/kaggle/working/datasets/test.txt', 'w') as f:\n",
    "    for expr in sample_expressions:\n",
    "        f.write(f\"{expr}\\n\")\n",
    "\n",
    "print(\"Created sample expressions dataset file\")\n",
    "\n",
    "# Load expressions from file (following the exact demo() function flow)\n",
    "with open(\"/kaggle/working/datasets/test.txt\") as f:\n",
    "    expr_strs = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f\"Loaded {len(expr_strs)} expressions from dataset\")\n",
    "\n",
    "# Build contrastive pairs\n",
    "print(\"Building contrastive pairs...\")\n",
    "try:\n",
    "    pairs = build_contrastive_pairs(expr_strs)\n",
    "    print(f\"Generated {len(pairs)} contrastive pairs\")\n",
    "\n",
    "    # storing the pairs in a file (exactly as in demo() function)\n",
    "    with open(\"/kaggle/working/datasets/contrastive_pairs.txt\", \"w\") as f:\n",
    "        for expr_a, expr_b, label in pairs:\n",
    "            f.write(f\"{expr_a} | {expr_b} | {label}\\n\")\n",
    "\n",
    "    print(\"Contrastive pairs saved to /kaggle/working/datasets/contrastive_pairs.txt\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error building contrastive pairs: {e}\")\n",
    "    print(\"‚ö†Ô∏è Will create a minimal pairs file for testing\")\n",
    "    \n",
    "    # Create minimal pairs for testing\n",
    "    with open(\"/kaggle/working/datasets/contrastive_pairs.txt\", \"w\") as f:\n",
    "        for i, expr in enumerate(sample_expressions[:3]):  # Use first 3 expressions\n",
    "            # Create simple positive and negative pairs\n",
    "            f.write(f\"{expr} | {expr} | 1\\n\")  # positive pair\n",
    "            if i < len(sample_expressions) - 1:\n",
    "                f.write(f\"{expr} | {sample_expressions[i+1]} | 0\\n\")  # negative pair\n",
    "    \n",
    "    print(\"Created minimal contrastive pairs file for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e0af5",
   "metadata": {},
   "source": [
    "## 6. TRAE Model Implementation\n",
    "\n",
    "Now let's implement the TRAE model and related components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables for optimal performance\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pytrs import (\n",
    "    Op,\n",
    "    VARIABLE_RANGE,\n",
    "    CONST_OFFSET,\n",
    "    PAREN_CLOSE,\n",
    "    PAREN_OPEN,\n",
    "    node_to_id,\n",
    "    parse_sexpr,\n",
    "    tokenize,\n",
    "    MAX_INT_TOKENS\n",
    ")\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    max_gen_length = 25122\n",
    "    vocab_size = CONST_OFFSET + MAX_INT_TOKENS + 2 + 1 + 1\n",
    "    start_token = CONST_OFFSET + MAX_INT_TOKENS\n",
    "    end_token = CONST_OFFSET + MAX_INT_TOKENS + 1\n",
    "    pad_token = CONST_OFFSET + MAX_INT_TOKENS + 2\n",
    "    cls_token = vocab_size\n",
    "    vocab_size += 1  # include CLS\n",
    "    \n",
    "    d_model = 256\n",
    "    num_heads = 8\n",
    "    num_encoder_layers = 4\n",
    "    num_decoder_layers = 4\n",
    "    dim_feedforward = 512\n",
    "    transformer_dropout = 0.2\n",
    "    max_seq_length = 25200\n",
    "    \n",
    "    batch_size = 16\n",
    "    learning_rate = 3e-4\n",
    "    epochs = 50\n",
    "    dropout_rate = 0.3\n",
    "    total_samples = 5000000\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expression processing helpers\n",
    "def dfs_traverse(expr, depth=0, node_list=None):\n",
    "    if node_list is None:\n",
    "        node_list = []\n",
    "    if isinstance(expr, Op):\n",
    "        node_list.append((PAREN_OPEN, depth))\n",
    "        node_list.append((expr, depth))\n",
    "        for child in expr.args:\n",
    "            dfs_traverse(child, depth + 1, node_list)\n",
    "        node_list.append((PAREN_CLOSE, depth))\n",
    "    else:\n",
    "        node_list.append((expr, depth))\n",
    "    return node_list\n",
    "\n",
    "def flatten_expr(expr):\n",
    "    node_list = dfs_traverse(expr, 0)\n",
    "    results = []\n",
    "    varmap = {}\n",
    "    intmap = {}\n",
    "    next_var_id = VARIABLE_RANGE[0]\n",
    "    next_int_id = CONST_OFFSET\n",
    "    for node_or_paren, depth in node_list:\n",
    "        if node_or_paren in (PAREN_OPEN, PAREN_CLOSE):\n",
    "            nid = node_or_paren\n",
    "        else:\n",
    "            nid, next_var_id, next_int_id, _ = node_to_id(\n",
    "                node_or_paren, varmap, intmap, next_var_id, next_int_id\n",
    "            )\n",
    "        results.append({\"node_id\": nid})\n",
    "    return results\n",
    "\n",
    "print(\"Expression processing helpers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fe8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1024):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "\n",
    "    def forward(self, x, positions=None):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        if positions is None:\n",
    "            positions = (\n",
    "                torch.arange(0, seq_len, device=x.device)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(batch_size, 1)\n",
    "            )\n",
    "        pos_emb = self.pos_embedding(positions)\n",
    "        return x + pos_emb\n",
    "\n",
    "print(\"PositionalEncoding defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe788834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer autoencoder\n",
    "class TransformerAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(config.vocab_size, config.d_model)\n",
    "        self.pos_encoder = PositionalEncoding(\n",
    "            config.d_model, max_len=config.max_seq_length\n",
    "        )\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config.d_model,\n",
    "            nhead=config.num_heads,\n",
    "            dim_feedforward=config.dim_feedforward,\n",
    "            dropout=config.transformer_dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, config.num_encoder_layers)\n",
    "\n",
    "        dec_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=config.d_model,\n",
    "            nhead=config.num_heads,\n",
    "            dim_feedforward=config.dim_feedforward,\n",
    "            dropout=config.transformer_dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, config.num_decoder_layers)\n",
    "        self.output_fc = nn.Linear(config.d_model, config.vocab_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_square_subsequent_mask(sz, device):\n",
    "        mask = (torch.triu(torch.ones(sz, sz, device=device)) == 1).T\n",
    "        mask = mask.float().masked_fill(mask == 0, float(\"-inf\")).masked_fill(\n",
    "            mask == 1, float(0.0)\n",
    "        )\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src_nodes, tgt_seq):\n",
    "        batch_size = src_nodes.size(0)\n",
    "        cls_column = torch.full(\n",
    "            (batch_size, 1), config.cls_token, dtype=torch.long, device=src_nodes.device\n",
    "        )\n",
    "        src_nodes_with_cls = torch.cat([cls_column, src_nodes], dim=1)\n",
    "\n",
    "        src_emb = self.token_embedding(src_nodes_with_cls)\n",
    "        src_emb = self.pos_encoder(src_emb)\n",
    "        memory = self.encoder(src_emb)\n",
    "\n",
    "        tgt_emb = self.token_embedding(tgt_seq)\n",
    "        tgt_emb = self.pos_encoder(tgt_emb)\n",
    "        tgt_mask = self.generate_square_subsequent_mask(\n",
    "            tgt_seq.size(1), device=tgt_seq.device\n",
    "        )\n",
    "\n",
    "        dec_out = self.decoder(tgt_emb, memory, tgt_mask=tgt_mask)\n",
    "        logits = self.output_fc(dec_out)\n",
    "        return logits\n",
    "\n",
    "    def encode(self, src_nodes):\n",
    "        batch_size = src_nodes.size(0)\n",
    "        cls_column = torch.full(\n",
    "            (batch_size, 1), config.cls_token, dtype=torch.long, device=src_nodes.device\n",
    "        )\n",
    "        src_nodes_with_cls = torch.cat([cls_column, src_nodes], dim=1)\n",
    "        src_emb = self.token_embedding(src_nodes_with_cls)\n",
    "        src_emb = self.pos_encoder(src_emb)\n",
    "        return self.encoder(src_emb)\n",
    "\n",
    "    def get_cls_vector(self, memory):\n",
    "        return memory[:, 0, :]\n",
    "\n",
    "print(\"TransformerAutoencoder defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb8945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAE wrapper\n",
    "class TRAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = TransformerAutoencoder()\n",
    "\n",
    "    def forward(self, src_nodes, src_pos, tgt_seq):\n",
    "        return self.model(src_nodes, tgt_seq)\n",
    "\n",
    "    @property\n",
    "    def encoder(self):\n",
    "        return self.model.encode\n",
    "\n",
    "    def get_cls_summary(self, memory):\n",
    "        return self.model.get_cls_vector(memory)\n",
    "\n",
    "# Projection head for contrastive learning\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, proj_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(proj_dim, proj_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print(\"TRAE and ProjectionHead defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3c1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def get_expression_cls_embedding(expr, model):\n",
    "    flat = flatten_expr(expr)\n",
    "    node_ids = [e[\"node_id\"] for e in flat]\n",
    "    if len(node_ids) + 1 > config.max_seq_length:\n",
    "        return None\n",
    "\n",
    "    src_tensor = torch.tensor([node_ids], dtype=torch.long, device=device)\n",
    "    memory = model.encoder(src_tensor)\n",
    "    return model.get_cls_summary(memory)\n",
    "\n",
    "def contrastive_loss(z1, z2, label, temperature=0.5):\n",
    "    # z1, z2: [batch, dim], label: [batch] (1=pos, 0=neg)\n",
    "    z1 = nn.functional.normalize(z1, dim=1)\n",
    "    z2 = nn.functional.normalize(z2, dim=1)\n",
    "    sim = torch.sum(z1 * z2, dim=1) / temperature\n",
    "    pos_loss = -nn.functional.logsigmoid(sim[label == 1]).mean() if (label == 1).any() else 0\n",
    "    neg_loss = -nn.functional.logsigmoid(-sim[label == 0]).mean() if (label == 0).any() else 0\n",
    "    return pos_loss + neg_loss\n",
    "\n",
    "print(\"Utility functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4947e4",
   "metadata": {},
   "source": [
    "## 7. Initialize and Train the Model\n",
    "\n",
    "Now let's initialize the TRAE model and train the projection head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7063f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "print(\"Initializing TRAE model...\")\n",
    "model = TRAE()\n",
    "model.eval()\n",
    "\n",
    "# Try to load pre-trained weights if available\n",
    "pretrained_model_path = None\n",
    "\n",
    "# First, check the repository path\n",
    "repo_model_path = '/kaggle/working/CHEHAB_FHE_Compiler_RL/RL/fhe_rl/trained_models/model_Transformer_ddp_10399047_epoch_5000000.pth'\n",
    "if os.path.exists(repo_model_path):\n",
    "    pretrained_model_path = repo_model_path\n",
    "    print(f\"Found model in repository: {pretrained_model_path}\")\n",
    "else:\n",
    "    # Fallback to Kaggle input datasets\n",
    "    for path in ['/kaggle/input/*/model_Transformer_ddp_10399047_epoch_5000000.pth']:\n",
    "        import glob\n",
    "        matches = glob.glob(path)\n",
    "        if matches:\n",
    "            pretrained_model_path = matches[0]\n",
    "            print(f\"Found model in Kaggle dataset: {pretrained_model_path}\")\n",
    "            break\n",
    "\n",
    "if pretrained_model_path:\n",
    "    print(f\"Loading pre-trained model from: {pretrained_model_path}\")\n",
    "    state_dict = torch.load(pretrained_model_path, map_location=device)\n",
    "    new_sd = {k[len(\"module.\"):] if k.startswith(\"module.\") else k: v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_sd)\n",
    "    print(\"Pre-trained Encoder loaded successfully\")\n",
    "else:\n",
    "    print(\"No pre-trained model found. Using randomly initialized weights.\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Initialize projection head\n",
    "print(\"\\nInitializing projection head...\")\n",
    "cls_dim = model.get_cls_summary(torch.zeros(1, 1, config.d_model, device=device)).shape[-1]\n",
    "projection_head = ProjectionHead(cls_dim, proj_dim=128).to(device)\n",
    "\n",
    "# Freeze encoder weights for projection head training\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(projection_head.parameters(), lr=1e-3)\n",
    "\n",
    "print(f\"Model initialized. CLS dimension: {cls_dim}\")\n",
    "print(f\"Projection head output dimension: 128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load contrastive pairs from the stored file (following demo() function exactly)\n",
    "print(\"Loading contrastive pairs for training...\")\n",
    "\n",
    "# Load the stored contrastive pairs from existing dataset file\n",
    "pairs = []\n",
    "with open(\"/kaggle/working/datasets/contrastive_pairs.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        expr_a_str, expr_b_str, label_str = line.strip().split(\" | \")\n",
    "        # Parse the expressions back to objects\n",
    "        expr_a = parse_sexpr(expr_a_str)\n",
    "        expr_b = parse_sexpr(expr_b_str)\n",
    "        label = int(label_str)\n",
    "        pairs.append((expr_a, expr_b, label))\n",
    "\n",
    "print(f\"Loaded {len(pairs)} training pairs from file\")\n",
    "\n",
    "# Count positive and negative pairs\n",
    "pos_pairs = sum(1 for _, _, label in pairs if label == 1)\n",
    "neg_pairs = sum(1 for _, _, label in pairs if label == 0)\n",
    "print(f\"Positive pairs: {pos_pairs}, Negative pairs: {neg_pairs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b73c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (exact demo() function implementation)\n",
    "print(\"Starting projection head training...\")\n",
    "\n",
    "# Training loop with tqdm progress bars\n",
    "for epoch in tqdm(range(10), desc=\"Training Epochs\"):\n",
    "    random.shuffle(pairs)\n",
    "    losses = []\n",
    "    \n",
    "    # Add progress bar for the training pairs within each epoch\n",
    "    epoch_pairs = tqdm(pairs, desc=f\"Epoch {epoch}\", leave=False)\n",
    "    \n",
    "    for expr_a, expr_b, label in epoch_pairs:\n",
    "        cls_a = get_expression_cls_embedding(expr_a, model)\n",
    "        cls_b = get_expression_cls_embedding(expr_b, model)\n",
    "        \n",
    "        if cls_a is None or cls_b is None:\n",
    "            continue\n",
    "        cls_a = cls_a.to(device)\n",
    "        cls_b = cls_b.to(device)\n",
    "        z_a = projection_head(cls_a)\n",
    "        z_b = projection_head(cls_b)\n",
    "        lbl = torch.tensor([label], dtype=torch.long, device=device)\n",
    "        loss = contrastive_loss(z_a, z_b, lbl)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Update progress bar with current loss\n",
    "        if len(losses) > 0:\n",
    "            epoch_pairs.set_postfix({\"loss\": f\"{losses[-1]:.6f}\", \"avg_loss\": f\"{np.mean(losses):.6f}\"})\n",
    "\n",
    "    print(f\"Epoch {epoch}: Contrastive loss = {np.mean(losses):.6f}\")\n",
    "\n",
    "# save the projection head\n",
    "torch.save(projection_head.state_dict(), \"/kaggle/working/projection_head.pth\")\n",
    "print(\"\\nProjection head training completed and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade10424",
   "metadata": {},
   "source": [
    "## 8. Test the Trained Model\n",
    "\n",
    "Now let's test the trained projection head on some example expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the projection head (test_projection_head function implementation)\n",
    "print(\"Testing the trained projection head...\")\n",
    "\n",
    "# Try to load saved projection head first\n",
    "try:\n",
    "    projection_head.load_state_dict(torch.load(\"/kaggle/working/projection_head.pth\", map_location=device))\n",
    "    projection_head.eval()\n",
    "    projection_head.to(device)\n",
    "    print(\"Loaded trained projection head\")\n",
    "except:\n",
    "    print(\"Using current projection head state\")\n",
    "\n",
    "exp_a = parse_sexpr(\"(Vec  (+ a b) (+ c d) (- f g) )\")\n",
    "exp_b = parse_sexpr(\"(Vec  (* a b) (* c d) (+ f g) )\")\n",
    "\n",
    "print(f\"Expression A: {exp_a}\")\n",
    "print(f\"Expression B: {exp_b}\")\n",
    "\n",
    "cls_a = get_expression_cls_embedding(exp_a, model)\n",
    "cls_b = get_expression_cls_embedding(exp_b, model)\n",
    "\n",
    "if cls_a is None or cls_b is None:\n",
    "    print(\"Cannot encode them\")\n",
    "else:\n",
    "    cls_a = cls_a.to(device)\n",
    "    cls_b = cls_b.to(device)\n",
    "    z_a = projection_head(cls_a)\n",
    "    z_b = projection_head(cls_b)\n",
    "\n",
    "    cosine_sim = nn.functional.cosine_similarity(z_a, z_b).item()\n",
    "    print(\"Cosine similarity between test expressions:\", cosine_sim)\n",
    "    print(\"Embedding for expr_a:\", z_a.cpu().detach().numpy())\n",
    "    print(\"Embedding for expr_b:\", z_b.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868ea163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with more expression pairs\n",
    "print(\"\\nüî¨ Testing multiple expression pairs...\")\n",
    "\n",
    "test_pairs_manual = [\n",
    "    (\"(Vec (+ a b) (+ c d) (- f g))\", \"(Vec (+ a b) (+ c d) (- f g))\", \"Identical\"),\n",
    "    (\"(Vec (+ a b) (+ c d) (- f g))\", \"(Vec (- a b) (- c d) (+ f g))\", \"Different ops\"),\n",
    "    (\"(+ a b)\", \"(- a b)\", \"Simple change\"),\n",
    "    (\"(* x y)\", \"(+ x y)\", \"Mult to add\"),\n",
    "    (\"(Vec (+ a b) (+ c d))\", \"(Vec (+ a b) (+ c d) (+ e f))\", \"Different length\")\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for expr1_str, expr2_str, description in test_pairs_manual:\n",
    "    try:\n",
    "        expr1 = parse_sexpr(expr1_str)\n",
    "        expr2 = parse_sexpr(expr2_str)\n",
    "        \n",
    "        cls1 = get_expression_cls_embedding(expr1, model)\n",
    "        cls2 = get_expression_cls_embedding(expr2, model)\n",
    "        \n",
    "        if cls1 is not None and cls2 is not None:\n",
    "            cls1 = cls1.to(device)\n",
    "            cls2 = cls2.to(device)\n",
    "            z1 = projection_head(cls1)\n",
    "            z2 = projection_head(cls2)\n",
    "            \n",
    "            cosine_sim = nn.functional.cosine_similarity(z1, z2).item()\n",
    "            euclidean_dist = torch.norm(z1 - z2).item()\n",
    "            \n",
    "            results.append({\n",
    "                'description': description,\n",
    "                'cosine_sim': cosine_sim,\n",
    "                'euclidean_dist': euclidean_dist,\n",
    "                'expr1': expr1_str[:30] + '...' if len(expr1_str) > 30 else expr1_str,\n",
    "                'expr2': expr2_str[:30] + '...' if len(expr2_str) > 30 else expr2_str\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n{description}:\")\n",
    "            print(f\"  Expr 1: {expr1_str}\")\n",
    "            print(f\"  Expr 2: {expr2_str}\")\n",
    "            print(f\"  Cosine similarity: {cosine_sim:.6f}\")\n",
    "            print(f\"  Euclidean distance: {euclidean_dist:.6f}\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå {description}: Failed to encode expressions\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå {description}: Error - {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Testing completed! Processed {len(results)} expression pairs successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfee9cb",
   "metadata": {},
   "source": [
    "## 9. Optional: Visualize Embeddings\n",
    "\n",
    "Let's create a simple visualization of the embeddings to understand how the model groups similar expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for visualization\n",
    "!pip install matplotlib seaborn scikit-learn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# Generate embeddings for a variety of expressions\n",
    "test_expressions = [\n",
    "    \"(+ a b)\",\n",
    "    \"(- a b)\", \n",
    "    \"(* a b)\",\n",
    "    \"(+ x y)\",\n",
    "    \"(- x y)\",\n",
    "    \"(* x y)\",\n",
    "    \"(Vec (+ a b) (+ c d))\",\n",
    "    \"(Vec (- a b) (- c d))\",\n",
    "    \"(Vec (* a b) (* c d))\",\n",
    "    \"(+ (+ a b) (+ c d))\",\n",
    "    \"(- (- a b) (- c d))\",\n",
    "    \"(* (* a b) (* c d))\"\n",
    "]\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "valid_expressions = []\n",
    "\n",
    "print(\"Generating embeddings for visualization...\")\n",
    "for expr_str in test_expressions:\n",
    "    try:\n",
    "        expr = parse_sexpr(expr_str)\n",
    "        cls_emb = get_expression_cls_embedding(expr, model)\n",
    "        \n",
    "        if cls_emb is not None:\n",
    "            cls_emb = cls_emb.to(device)\n",
    "            z = projection_head(cls_emb)\n",
    "            embeddings.append(z.cpu().detach().numpy().flatten())\n",
    "            \n",
    "            # Create labels based on operation type\n",
    "            if '+' in expr_str:\n",
    "                labels.append('Addition')\n",
    "            elif '-' in expr_str:\n",
    "                labels.append('Subtraction')\n",
    "            elif '*' in expr_str:\n",
    "                labels.append('Multiplication')\n",
    "            else:\n",
    "                labels.append('Other')\n",
    "                \n",
    "            valid_expressions.append(expr_str)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {expr_str}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Generated {len(embeddings)} embeddings for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(embeddings) > 0:\n",
    "    # Convert to numpy array\n",
    "    embeddings_array = np.array(embeddings)\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction\n",
    "    pca = PCA(n_components=2)\n",
    "    embeddings_2d = pca.fit_transform(embeddings_array)\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot PCA\n",
    "    plt.subplot(1, 2, 1)\n",
    "    unique_labels = list(set(labels))\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))\n",
    "    \n",
    "    for i, label in enumerate(unique_labels):\n",
    "        mask = np.array(labels) == label\n",
    "        plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "                   c=[colors[i]], label=label, s=100, alpha=0.7)\n",
    "    \n",
    "    plt.title('Expression Embeddings (PCA)', fontsize=14)\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Create similarity heatmap\n",
    "    plt.subplot(1, 2, 2)\n",
    "    similarity_matrix = np.zeros((len(embeddings), len(embeddings)))\n",
    "    \n",
    "    for i in range(len(embeddings)):\n",
    "        for j in range(len(embeddings)):\n",
    "            emb_i = torch.tensor(embeddings[i]).unsqueeze(0)\n",
    "            emb_j = torch.tensor(embeddings[j]).unsqueeze(0)\n",
    "            similarity = nn.functional.cosine_similarity(emb_i, emb_j).item()\n",
    "            similarity_matrix[i, j] = similarity\n",
    "    \n",
    "    # Create abbreviated labels for the heatmap\n",
    "    short_labels = [expr[:15] + '...' if len(expr) > 15 else expr for expr in valid_expressions]\n",
    "    \n",
    "    sns.heatmap(similarity_matrix, \n",
    "                xticklabels=short_labels,\n",
    "                yticklabels=short_labels,\n",
    "                annot=True, \n",
    "                fmt='.2f',\n",
    "                cmap='coolwarm',\n",
    "                center=0,\n",
    "                square=True)\n",
    "    plt.title('Cosine Similarity Heatmap', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/kaggle/working/embedding_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Visualization Summary:\")\n",
    "    print(f\"- PCA explains {pca.explained_variance_ratio_.sum():.2%} of the variance in the first 2 components\")\n",
    "    print(f\"- Similarity matrix shows how similar expressions cluster together\")\n",
    "    print(f\"- Visualization saved as /kaggle/working/embedding_analysis.png\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No valid embeddings generated for visualization\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
